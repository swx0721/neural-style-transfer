# fast_style_transfer_train.py (MindSpore å¿«é€Ÿé£æ ¼è¿ç§»è®­ç»ƒè„šæœ¬ - æœ€ç»ˆå®Œæ•´ä¿®æ­£ç‰ˆ)

import mindspore as ms
# ğŸŒŸ ä¿®æ­£ 1ï¼šæ·»åŠ  load_param_into_net å¯¼å…¥
from mindspore import nn, ops, context, Tensor, save_checkpoint, load_checkpoint, load_param_into_net, Parameter 
from mindspore.nn import Adam
from mindspore import dtype as mstype
import numpy as np
import time
import yaml
import argparse
import sys
import os

# ç¡®ä¿ src/ åœ¨è·¯å¾„ä¸­ä»¥ä¾¿å¯¼å…¥ StyleGenerator, VGG19, GramMatrix
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'src'))

# å¯¼å…¥æ‰€æœ‰å¿…è¦çš„ç»„ä»¶
from src.train_model import StyleGenerator, VGG19, GramMatrix, NSTLoss
from src.anime_dataloader import create_dataloader 
from src.process_image import load_image, tensor_convert 

# VGG19 æƒé‡æ–‡ä»¶è·¯å¾„å®šä¹‰ (ç”¨äº TotalLossNet ä¸­çš„ VGG19 å®ä¾‹åŒ–)
VGG19_CHECKPOINT_PATH = './vgg19-5104d1ea-910v2.ckpt' 

# --- Global MindSpore Context Setup ---
# è¿è¡Œåœ¨ CPUï¼Œä½¿ç”¨ PYNATIVE_MODE é¿å… VGG19 ç¼–è¯‘é—®é¢˜
# âš ï¸ æ³¨æ„ï¼šCPU è®­ç»ƒéå¸¸æ…¢ï¼Œå»ºè®®åˆ‡æ¢åˆ° GPU ç¯å¢ƒ
context.set_context(mode=context.PYNATIVE_MODE, device_target="CPU")


class TotalLossNet(nn.Cell):
    """
    MindSpore Cellï¼Œç”¨äºè®¡ç®—è®­ç»ƒ StyleGenerator æ‰€éœ€çš„ Content Loss å’Œ Style Lossã€‚
    """
    def __init__(self, generator, avg_style_ckpt_path, config):
        super(TotalLossNet, self).__init__()
        self.generator = generator
        
        # 1. å®ä¾‹åŒ– VGG19 å¹¶åŠ è½½æƒé‡
        self.vgg19 = VGG19(requires_grad=False)
        
        # åŠ è½½ VGG19 é¢„è®­ç»ƒæƒé‡
        if not os.path.exists(VGG19_CHECKPOINT_PATH):
            raise FileNotFoundError(f"Error: VGG19 checkpoint not found at {VGG19_CHECKPOINT_PATH}")
            
        print(f"[VGG19] Loading weights from: {VGG19_CHECKPOINT_PATH}")
        param_dict = load_checkpoint(VGG19_CHECKPOINT_PATH)
        
        # ğŸŒŸ å…³é”®ä¿®æ­£ 2ï¼šå¤„ç† VGG19 Checkpoint é”®åä¸­çš„ 'vgg19.' å‰ç¼€
        new_param_dict = {}
        for name, param in param_dict.items():
            # ç§»é™¤ MindSpore VGG19 Checkpoint ä¸­å¸¸è§çš„ 'vgg19.' å‰ç¼€
            if name.startswith('vgg19.'):
                new_name = name[len('vgg19.'):]
            else:
                new_name = name
            new_param_dict[new_name] = param
            
        load_param_into_net(self.vgg19, new_param_dict)
        self.vgg19.set_train(False)
        print("[VGG19] VGG19 Weights loaded successfully.")
        
        # 2. ä» Checkpoint åŠ è½½å¹³å‡ Gram çŸ©é˜µ (å›ºå®šé£æ ¼ç›®æ ‡)
        print(f"[LossNet] Loading average Gram features from: {avg_style_ckpt_path}")
        if not os.path.exists(avg_style_ckpt_path):
            raise FileNotFoundError(f"Error: Average style checkpoint not found at {avg_style_ckpt_path}")
            
        param_dict = load_checkpoint(avg_style_ckpt_path)
        
        style_features = {}
        for param_name, param in param_dict.items():
            layer_name = param_name.replace('avg_gram_', '')
            style_features[layer_name] = param.data
            
        if not style_features:
            raise ValueError(f"Error: No style features loaded from {avg_style_ckpt_path}")
            
        print("[LossNet] Average Gram features loaded successfully.")
        
        # 3. å®ä¾‹åŒ–æŸå¤±ç½‘ç»œ
        
        # ğŸŒŸ å…³é”®ä¿®æ­£ 3ï¼šåˆ›å»ºä¸€ä¸ªå ä½ç¬¦ Content Feature å­—å…¸ï¼Œç”¨äºé€šè¿‡ NSTLoss.__init__ æ£€æŸ¥
        # ç¡®ä¿ Content Target é”® 'relu4_1' å­˜åœ¨ï¼Œé¿å… KeyError
        dummy_content_features = {
            'relu4_1': ms.Tensor(0.0, mstype.float32) 
        }

        self.nst_loss = NSTLoss(
            style_features=style_features,
            content_features=dummy_content_features, # ä¼ å…¥å ä½ç¬¦
            style_weights=config['style_weights'],
            content_weight=config['alpha'],
            style_weight=config['beta']
        )
        
    def construct(self, content_tensor):
        # 1. ç”Ÿæˆé£æ ¼åŒ–å›¾åƒ
        generated_tensor = self.generator(content_tensor)
        
        # 2. æå– Content å›¾åƒå’Œ Generated å›¾åƒçš„ VGG19 ç‰¹å¾
        content_features = self.vgg19(content_tensor)
        generated_features = self.vgg19(generated_tensor)
        
        # 3. è®¡ç®—æŸå¤±
        # MindSpore VGG19 çš„è¾“å‡ºç‰¹å¾çš„é”®åæ˜¯ 'reluX_Y'
        # ğŸŒŸ è¿™é‡Œçš„èµ‹å€¼ä¼šè¦†ç›– NSTLoss.__init__ ä¸­è®¾ç½®çš„è™šæ‹Ÿå€¼
        self.nst_loss.content_target = content_features['relu4_1']
        
        # è®¡ç®—æ€»æŸå¤±
        total_loss = self.nst_loss(generated_features)
        
        return total_loss
        

def train_generator(config):
    """ä¸»è®­ç»ƒå‡½æ•°"""
    
    # 1. åˆå§‹åŒ–æ¨¡å‹
    generator = StyleGenerator()
    
    # 2. åˆå§‹åŒ–ä¼˜åŒ–å™¨
    optimizer = Adam(generator.trainable_params(), learning_rate=config['learning_rate'])
    
    # 3. åˆ›å»º DataLoader
    print(f"Loading data from: {config['content_image_dir']}")
    dataloader = create_dataloader(
        config['content_image_dir'], 
        batch_size=config['batch_size'],
        image_size=config['image_size'],
        # å¼ºåˆ¶è®¾ç½® num_workers=1
        num_workers=1 
    )

    total_batches = dataloader.get_dataset_size()
    print(f"Total batches per epoch: {total_batches}")
    
    # 4. åˆå§‹åŒ–æŸå¤±ç½‘ç»œå’Œè®­ç»ƒæ­¥éª¤
    # åœ¨è¿™é‡Œåˆå§‹åŒ– LossNetï¼Œå®ƒä¼šåŠ è½½ VGG19 å’Œ Style Gram ç‰¹å¾
    loss_net = TotalLossNet(generator, config['avg_style_ckpt_path'], config)
    
    # å°è£…è®­ç»ƒæ­¥éª¤
    train_step = nn.TrainOneStepCell(loss_net, optimizer)
    
    print("Starting training loop...")
    
    # 5. è®­ç»ƒå¾ªç¯
    for epoch in range(1, config['num_epochs'] + 1):
        epoch_start_time = time.time()
        
        # é‡ç½®æŸå¤±ç»Ÿè®¡
        running_loss = 0.0
        
        # éå† dataloader
        for batch_idx, data in enumerate(dataloader.create_tuple_iterator()):
            content_tensor = data[0]

            # ğŸŒŸ å…³é”®ä¿®æ­£ï¼šç¡®ä¿è¿™é‡Œæ²¡æœ‰ 'if batch_idx >= 5: break' è¿™æ ·çš„è°ƒè¯•ä»£ç ï¼
            
            # æ‰§è¡Œä¸€æ­¥è®­ç»ƒ
            loss = train_step(content_tensor)
            loss_value = loss.asnumpy().item()
            running_loss += loss_value

            # æ—¥å¿—æ‰“å°
            if (batch_idx + 1) % config['log_interval'] == 0:
                print(f"Epoch: {epoch}/{config['num_epochs']}, Batch: {batch_idx + 1}/{total_batches}, Loss: {loss_value:.4f}")
                
        # 6. Epoch ç»“æŸ
        avg_loss = running_loss / total_batches
        epoch_duration = time.time() - epoch_start_time
        print(f"\n--- Epoch {epoch} finished. Avg Loss: {avg_loss:.4f}, Duration: {epoch_duration:.2f}s ---\n")
        
        # 7. ä¿å­˜ Checkpoint
        if epoch % config['save_interval'] == 0:
            os.makedirs(config['output_dir'], exist_ok=True)
            ckpt_name = f"generator_epoch_{epoch}.ckpt"
            ckpt_path = os.path.join(config['output_dir'], ckpt_name)
            
            # åªä¿å­˜ StyleGenerator çš„å‚æ•°
            save_checkpoint(generator, ckpt_path)
            print(f"Checkpoint saved to: {ckpt_path}")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="MindSpore Fast Style Transfer Training")
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--content_image_dir", type=str, required=True, help="Directory containing the content images.")
    parser.add_argument("--avg_style_ckpt_path", type=str, required=True, help="Path to the pre-calculated average style checkpoint (.ckpt).")
    
    parser.add_argument("--output_dir", type=str, default="checkpoints", help="Directory to save model checkpoints.")
    parser.add_argument("--train_config_path", type=str, required=True, help="Path to training configuration file (.yaml).")
    
    # å¯é€‰å‚æ•° (è¦†ç›– YAML)
    parser.add_argument("--num_epochs", type=int, help="Number of training epochs (overrides YAML).")
    parser.add_argument("--learning_rate", type=float, help="Learning rate (overrides YAML).")
    parser.add_argument("--log_interval", type=int, default=1, help="Log loss every N batches.")
    parser.add_argument("--save_interval", type=int, default=10, help="Save checkpoint every N epochs.")
    
    args = parser.parse_args()
    
    # 1. åŠ è½½ YAML é…ç½®
    try:
        # ä¿®å¤ï¼šæ˜¾å¼æŒ‡å®šç¼–ç ä¸º UTF-8
        with open(args.train_config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        print(f"Error loading config file {args.train_config_path}: {e}")
        print("Please ensure your YAML file is encoded in UTF-8.")
        sys.exit(1)
        
    # 2. åˆå¹¶å‘½ä»¤è¡Œå‚æ•°å¹¶è®¾ç½®é…ç½®
    config['content_image_dir'] = args.content_image_dir
    config['avg_style_ckpt_path'] = args.avg_style_ckpt_path 
    config['output_dir'] = args.output_dir
    
    # è¦†ç›– YAML ä¸­çš„ num_epochs/lr/log_interval/save_interval
    if args.num_epochs is not None:
        config['num_epochs'] = args.num_epochs
    if args.learning_rate is not None:
        config['learning_rate'] = args.learning_rate
    if args.log_interval is not None:
        config['log_interval'] = args.log_interval
    if args.save_interval is not None:
        config['save_interval'] = args.save_interval
        
    # 3. å¼€å§‹è®­ç»ƒ
    train_generator(config)