# video.py (MindSpore CPU æœ€ç»ˆä¿®æ­£ç‰ˆ - åŒ…å«é¢„çƒ­)
import utils
import transformer
import cv2
import os
import time
import mindspore as ms
from mindspore import context, Tensor
import numpy as np

# ------------------ GLOBAL SETTINGS ------------------
# MindSpore CPU ç¯å¢ƒè®¾ç½®
target_device = "CPU"
context.set_context(mode=context.GRAPH_MODE, device_target=target_device) # è§†é¢‘æ‰¹é‡å¤„ç†ä½¿ç”¨GRAPH_MODEæ±‚æœ€å¤§ååé‡

VIDEO_NAME = "input_video.mp4"       # å¾…å¤„ç†çš„è§†é¢‘æ–‡ä»¶å
FRAME_SAVE_PATH = "frames/temp/"     # è§†é¢‘å¸§æå–çš„ä¸´æ—¶ç›®å½•
STYLE_FRAME_SAVE_PATH = "style_frames/output/" # é£æ ¼åŒ–å¸§çš„è¾“å‡ºç›®å½•
STYLE_VIDEO_NAME = "styled_output.mp4" # æœ€ç»ˆè¾“å‡ºçš„è§†é¢‘æ–‡ä»¶å
STYLE_PATH = "models/checkpoint_29250.ckpt" # æ‚¨çš„é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
PRESERVE_COLOR = False                   # ç¡®ä¿å…³é—­è‰²å½©è¿ç§»

FRAME_BASE_FILE_NAME = "frame"
FRAME_BASE_FILE_TYPE = ".jpg"
TRAIN_IMAGE_SIZE = 256 # åŒ¹é… train.py ä¸­çš„è®­ç»ƒå°ºå¯¸

# ------------------ è¾…åŠ©å‡½æ•° (çº¯ Python/OpenCV) ------------------
def getInfo(video_path):
    # ... (getInfo ä¿æŒä¸å˜) ...
    vidcap = cv2.VideoCapture(video_path)
    if not vidcap.isOpened():
        raise IOError(f"Cannot open video file {video_path}")
    width = vidcap.get(cv2.CAP_PROP_FRAME_WIDTH )
    height = vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT )
    fps =  vidcap.get(cv2.CAP_PROP_FPS)
    vidcap.release()
    return int(height), int(width), fps

def getFrames(video_path, frames_path=FRAME_SAVE_PATH):
    # ... (getFrames ä¿æŒä¸å˜) ...
    os.makedirs(frames_path, exist_ok=True)
    vidcap = cv2.VideoCapture(video_path)
    count = 0
    while True:
        success, image = vidcap.read()
        if not success:
            break
        cv2.imwrite(os.path.join(frames_path, f"{FRAME_BASE_FILE_NAME}{count:06d}{FRAME_BASE_FILE_TYPE}"), image)
        count += 1
    vidcap.release()
    print(f"âœ… æå–äº† {count} å¸§.")

def createVideo(frames_path, save_name, fps, height, width):    
    # ... (createVideo ä¿æŒä¸å˜) ...
    base_name_len = len(FRAME_BASE_FILE_NAME)
    filetype_len = len(FRAME_BASE_FILE_TYPE)
    # ç¡®ä¿è‡ªç„¶æ’åº
    images = [img for img in sorted(os.listdir(frames_path), key=lambda x : int(x[base_name_len:-filetype_len])) if img.endswith(FRAME_BASE_FILE_TYPE)]
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v') 
    out = cv2.VideoWriter(save_name, fourcc, fps, (int(width), int(height)))
    
    for image in images:
        img_path = os.path.join(frames_path, image)
        frame = cv2.imread(img_path)
        if frame is not None:
            # å…¼å®¹æ€§æ£€æŸ¥ï¼šç¡®ä¿å¸§å°ºå¯¸åŒ¹é…ï¼Œå¦åˆ™éœ€è¦é‡æ–°resize
            if frame.shape[0] != height or frame.shape[1] != width:
                 frame = cv2.resize(frame, (width, height))
            out.write(frame)

    out.release()
    print(f"âœ… è§†é¢‘å·²ä¿å­˜è‡³ {save_name}")

# ------------------ æ ¸å¿ƒæ¨ç†é€»è¾‘ ------------------
def stylize_frames(net, frame_folder, output_folder):
    """ å¯¹ä¸€ä¸ªæ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰å¸§è¿›è¡Œé£æ ¼è¿ç§» """
    os.makedirs(output_folder, exist_ok=True)
    image_ext = ('.jpg', '.jpeg', '.png', '.bmp')
    # ä½¿ç”¨ sorted ç¡®ä¿å¤„ç†é¡ºåº
    image_paths = sorted([
        os.path.join(frame_folder, f)
        for f in os.listdir(frame_folder)
        if f.lower().endswith(image_ext)
    ])
    
    if not image_paths:
        print("âš  æ–‡ä»¶å¤¹å†…æœªæ£€æµ‹åˆ°å›¾åƒæ–‡ä»¶ï¼Œè·³è¿‡é£æ ¼åŒ–ã€‚")
        return

    total_frames = len(image_paths)
    start_time = time.time()
    
    # é¢„çƒ­å·²åœ¨ä¸»å‡½æ•°ä¸­å®Œæˆ

    for idx, img_path in enumerate(image_paths):
        content_image = utils.load_image(img_path)
        if content_image is None:
            print(f"âŒ è·³è¿‡æ— æ•ˆå›¾åƒ: {img_path}")
            continue

        # ********** çº¯å‡€æ¨ç†æµç¨‹ **********
        content_tensor = utils.itot(content_image, max_size=None)
        generated_tensor = net(content_tensor)
        generated_image = utils.ttoi(generated_tensor)
        
        # ä¿æŒçº¯å‡€è¾“å‡º
        if PRESERVE_COLOR:
            generated_image = utils.transfer_color(content_image, generated_image)
        # **********************************

        output_filename = os.path.basename(img_path)
        output_path = os.path.join(output_folder, output_filename)
        utils.saveimg(generated_image, output_path)

        if idx % 100 == 0:
            avg_time = (time.time() - start_time) / (idx + 1)
            print(f"â–¶ å¸§å¤„ç†è¿›åº¦: {idx+1}/{total_frames}. å¹³å‡å¸§å¤„ç†æ—¶é—´: {avg_time*1000:.2f} ms")

# ------------------ ä¸»å‡½æ•° ------------------
def video_transfer(video_path, style_path):
    starttime = time.time()
    
    # 1. æå–è§†é¢‘ä¿¡æ¯
    H_orig, W_orig, fps = getInfo(video_path)
    print(f"ğŸ“¼ è§†é¢‘ä¿¡æ¯: H={H_orig}, W={W_orig}, FPS={fps:.2f}")

    # 2. å¸§æå–
    print("â³ æå–è§†é¢‘å¸§...")
    getFrames(video_path, frames_path=FRAME_SAVE_PATH)
    
    # 3. åŠ è½½ç½‘ç»œ
    net = transformer.TransformerNet()
    param_dict = ms.load_checkpoint(style_path)
    ms.load_param_into_net(net, param_dict)
    net.set_train(False)
    print("âœ… Transformer Network Loaded.")
    
    # ********** é¢„çƒ­æ­¥éª¤ **********
    print(f"ğŸ”¥ æ­£åœ¨é¢„çƒ­ç½‘ç»œ (Warm-up)... (ç›®æ ‡å°ºå¯¸: {TRAIN_IMAGE_SIZE})")
    dummy_image = np.zeros((TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE, 3), dtype=np.uint8)
    dummy_tensor = utils.itot(dummy_image, max_size=None)
    _ = net(dummy_tensor)
    print("âœ… é¢„çƒ­å®Œæˆï¼Œå¼€å§‹é£æ ¼åŒ–ã€‚")
    # ******************************

    # 4. å¯¹å¸§è¿›è¡Œé£æ ¼è¿ç§» (æ³¨æ„ï¼šè¾“å‡ºå¸§å°ºå¯¸ä¸º TRAIN_IMAGE_SIZE x TRAIN_IMAGE_SIZE)
    print("ğŸ¨ æ­£åœ¨å¯¹å¸§è¿›è¡Œé£æ ¼è¿ç§»...")
    stylize_frames(net, FRAME_SAVE_PATH, STYLE_FRAME_SAVE_PATH)
    
    # 5. åˆæˆè§†é¢‘ (ä½¿ç”¨ TRAIN_IMAGE_SIZE ä½œä¸ºè§†é¢‘å°ºå¯¸)
    print("ğŸ¬ æ­£åœ¨åˆæˆè§†é¢‘...")
    createVideo(STYLE_FRAME_SAVE_PATH, STYLE_VIDEO_NAME, fps, TRAIN_IMAGE_SIZE, TRAIN_IMAGE_SIZE)

    stop_time = time.time()
    print(f"\nâœ¨ è§†é¢‘é£æ ¼è¿ç§»å®Œæˆ! æ€»è€—æ—¶: {stop_time - starttime:.2f} ç§’")

if __name__ == '__main__':
    if not os.path.exists(STYLE_PATH):
         print(f"âŒ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {STYLE_PATH}")
         STYLE_PATH = input("è¯·è¾“å…¥æ­£ç¡®çš„ checkpoint è·¯å¾„ï¼š").strip()
    video_transfer(VIDEO_NAME, STYLE_PATH)